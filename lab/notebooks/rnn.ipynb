{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "rnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5o52nzI3dbk"
      },
      "source": [
        "import sys\r\n",
        "import re\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import keras\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, LSTM\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8QkpvXG2PjH"
      },
      "source": [
        "text = open('./Москва-Петушки.txt', 'r', encoding='utf-8').read()\r\n",
        "text = text.lower()\r\n",
        "text = re.sub(r'[^а-я\\s\\d.!\\?-]+', '', text)\r\n",
        "text = re.sub(r'[!\\?]+', '.', text)\r\n",
        "text = re.sub(r'\\s+', ' ', text)\r\n",
        "\r\n",
        "chars = sorted(list(set(text)))\r\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\r\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\r\n",
        "\r\n",
        "n_chars = len(text)\r\n",
        "n_vocab = len(chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZNWmUMN2bNT",
        "outputId": "dcdef49a-8a43-4946-b3e9-2300032ab385"
      },
      "source": [
        "max_sentence_length = 100\r\n",
        "window_length = 25\r\n",
        "step = 1\r\n",
        "dataX = []\r\n",
        "dataY = []\r\n",
        "for sentence in text.split('.'):\r\n",
        "  if len(sentence) == 0:\r\n",
        "    continue\r\n",
        "  sentence += '.'\r\n",
        "  for i in range(0, min(len(sentence), max_sentence_length) - window_length, step):\r\n",
        "    seq_in = sentence[i:i + window_length]\r\n",
        "    seq_out = sentence[i + window_length]\r\n",
        "    dataX.append(seq_in)\r\n",
        "    dataY.append(seq_out)\r\n",
        "n_sentences = len(dataX)\r\n",
        "X = np.zeros((n_sentences, window_length, n_vocab), dtype=np.bool)\r\n",
        "y = np.zeros((n_sentences, n_vocab), dtype=np.bool)\r\n",
        "for i, sentence in enumerate(dataX):\r\n",
        "    for t, char in enumerate(sentence):\r\n",
        "      X[i, t, char_to_int[char]] = 1\r\n",
        "    y[i, char_to_int[dataY[i]]] = 1\r\n",
        "print('X shape:', X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape: (90987, 25, 45)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMDFAWr-X8aJ",
        "outputId": "b3e4386a-bc76-404b-f6ac-0226f9c5d6f5"
      },
      "source": [
        "len(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "195760"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd7_bSdr2gVT"
      },
      "source": [
        "model = keras.Sequential(\r\n",
        "    [\r\n",
        "        LSTM(256, input_shape=X.shape[1:], return_sequences=True),\r\n",
        "        Dropout(0.2),\r\n",
        "        LSTM(256),\r\n",
        "        Dropout(0.2),\r\n",
        "        Dense(y.shape[1], activation='softmax')\r\n",
        "    ]\r\n",
        ")\r\n",
        "filename = \"rnn.hdf5\"\r\n",
        "# model.load_weights(filename)\r\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer='adam')\r\n",
        "model.fit(X, y, batch_size=128, epochs=40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSl3mHPA9ws1"
      },
      "source": [
        "def sample(preds, temperature=1.0):\r\n",
        "    preds = np.asarray(preds).astype(\"float64\")\r\n",
        "    preds = np.log(preds) / temperature\r\n",
        "    exp_preds = np.exp(preds)\r\n",
        "    preds = exp_preds / np.sum(exp_preds)\r\n",
        "    probas = np.random.multinomial(1, preds, 1)\r\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7_nF3rn2sMB",
        "outputId": "06e31abd-618b-4787-9177-b451fbf9923b"
      },
      "source": [
        "start = np.random.randint(0, n_sentences - 1)\r\n",
        "temperature = 0.1\r\n",
        "generated = \"\"\r\n",
        "pattern = dataX[start]\r\n",
        "print('...Generating with seed: \"' + pattern + '\"')\r\n",
        "for i in range(100):\r\n",
        "    x_pred = np.zeros((1, window_length, n_vocab))\r\n",
        "    for t, char in enumerate(pattern):\r\n",
        "        x_pred[0, t, char_to_int[char]] = 1.0\r\n",
        "    preds = model.predict(x_pred, verbose=0)[0]\r\n",
        "    next_char = int_to_char[sample(preds, temperature)]\r\n",
        "    pattern = pattern[1:] + next_char\r\n",
        "    sys.stdout.write(next_char)\r\n",
        "    if next_char == '.':\r\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "...Generating with seed: \"го карачарова от серпа и \"\n",
            "молота до карачарова мой бог не мог было приняли давайте и написал ни любить на свете положением сто"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkPYDQ5cBrSv"
      },
      "source": [
        "\r\n",
        "model.save('rnn.hdf5', save_format='hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGzuwETM-U2m"
      },
      "source": [
        "### Markov chain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jla1C1Hg-YrE"
      },
      "source": [
        "from collections import defaultdict\r\n",
        "\r\n",
        "markov_window_length = 5\r\n",
        "step = 1\r\n",
        "markov_dataX = []\r\n",
        "markov_dataY = []\r\n",
        "for sentence in text.split('.'):\r\n",
        "  if len(sentence) == 0:\r\n",
        "    continue\r\n",
        "  sentence += '.'\r\n",
        "  for i in range(0, min(len(sentence), max_sentence_length) - markov_window_length, step):\r\n",
        "    seq_in = sentence[i:i + markov_window_length]\r\n",
        "    seq_out = sentence[i + markov_window_length]\r\n",
        "    markov_dataX.append(seq_in)\r\n",
        "    markov_dataY.append(seq_out)\r\n",
        "\r\n",
        "nodes = defaultdict(lambda: defaultdict(lambda: 0))\r\n",
        "for sentence, symbol in zip(markov_dataX, markov_dataY):\r\n",
        "  nodes[sentence][symbol] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eRrH9AeHgFH",
        "outputId": "fb4a8ea0-504f-44df-dbcb-479db9b4a677"
      },
      "source": [
        "start = np.random.randint(0, len(markov_dataX) - 1)\r\n",
        "\r\n",
        "pattern = markov_dataX[start]\r\n",
        "print('...Generating with seed: \"' + pattern + '\"')\r\n",
        "for i in range(100):\r\n",
        "    next_chars_pool = [symbol for symbol in nodes[pattern]]\r\n",
        "    probas = np.array([w for w in nodes[pattern].values()])\r\n",
        "    probas = probas / probas.sum()\r\n",
        "    if len(probas) == 0:\r\n",
        "      break\r\n",
        "    next_char = next_chars_pool[np.argmax(np.random.multinomial(1, probas, 1))]\r\n",
        "    pattern = pattern[1:] + next_char\r\n",
        "    sys.stdout.write(next_char)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "...Generating with seed: \"а там\"\n",
            " сосна он плотно и как же."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1cxaHC0YfkS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}